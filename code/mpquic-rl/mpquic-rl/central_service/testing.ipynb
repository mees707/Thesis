{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory containing your custom modules\n",
    "custom_module_path = \"\"\n",
    "\n",
    "# Get the current value of PYTHONPATH (if any)\n",
    "existing_pythonpath = os.environ.get(\"PYTHONPATH\", \"\")\n",
    "\n",
    "# Append your custom module path to PYTHONPATH\n",
    "os.environ[\"PYTHONPATH\"] = f\"{custom_module_path}:{existing_pythonpath}\"\n",
    "\n",
    "# Now Python will search for modules in the specified directory\n",
    "print(existing_pythonpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym as gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class SimpleMultiAgentEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(SimpleMultiAgentEnv, self).__init__()\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.state = np.array([0.5, 0.5])\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = np.array([0.5, 0.5])\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, actions):\n",
    "        rewards = [0, 0]\n",
    "        done = False\n",
    "        \n",
    "        for i, action in enumerate(actions):\n",
    "            if action == 0:\n",
    "                self.state[i] -= 0.1\n",
    "            else:\n",
    "                self.state[i] += 0.1\n",
    "                \n",
    "            rewards[i] = -abs(self.state[i] - 0.5)  # reward is higher when closer to 0.5\n",
    "        \n",
    "        return self.state, rewards, done, {}\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "# Instantiate the environment\n",
    "env = SimpleMultiAgentEnv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "    \n",
    "    def act(self):\n",
    "        return self.action_space.sample()\n",
    "\n",
    "agent1 = RandomAgent(env.action_space)\n",
    "agent2 = RandomAgent(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: [0.5 0.5]\n",
      "Step 1 - State: [0.6 0.4], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 2 - State: [0.7 0.5], Rewards: [-0.19999999999999996, -0.0]\n",
      "Step 3 - State: [0.8 0.6], Rewards: [-0.29999999999999993, -0.09999999999999998]\n",
      "Step 4 - State: [0.9 0.5], Rewards: [-0.3999999999999999, -0.0]\n",
      "Step 5 - State: [1.  0.4], Rewards: [-0.4999999999999999, -0.09999999999999998]\n",
      "Step 6 - State: [1.1 0.3], Rewards: [-0.5999999999999999, -0.19999999999999996]\n",
      "Step 7 - State: [1.  0.4], Rewards: [-0.4999999999999999, -0.09999999999999998]\n",
      "Step 8 - State: [1.1 0.3], Rewards: [-0.5999999999999999, -0.19999999999999996]\n",
      "Step 9 - State: [1.  0.2], Rewards: [-0.4999999999999999, -0.29999999999999993]\n",
      "Step 10 - State: [0.9 0.1], Rewards: [-0.3999999999999999, -0.39999999999999997]\n",
      "Simulation completed.\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to simulate\n",
    "num_steps = 10\n",
    "\n",
    "# Reset the environment\n",
    "state = env.reset()\n",
    "print(f\"Initial state: {state}\")\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Agents take actions\n",
    "    action1 = agent1.act()\n",
    "    action2 = agent2.act()\n",
    "    \n",
    "    # Step the environment\n",
    "    state, rewards, done, info = env.step([action1, action2])\n",
    "    \n",
    "    print(f\"Step {step + 1} - State: {state}, Rewards: {rewards}\")\n",
    "\n",
    "print(\"Simulation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: [0.5 0.5]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 0:\n",
      "Performance of RandomAgent: -9.039999999999997\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 1 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 2 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 3 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 4 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 5 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 6 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 7 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 8 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 9 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 10 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 10:\n",
      "Performance of RandomAgent: -8.079999999999998\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 11 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 12 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 13 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 14 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 15 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 16 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 17 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 18 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 19 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 20 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 20:\n",
      "Performance of RandomAgent: -8.679999999999998\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 21 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 22 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 23 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 24 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 25 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 26 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 27 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 28 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 29 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 30 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 30:\n",
      "Performance of RandomAgent: -8.599999999999998\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 31 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 32 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 33 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 34 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 35 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 36 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 37 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 38 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 39 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 40 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 40:\n",
      "Performance of RandomAgent: -10.039999999999997\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 41 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 42 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 43 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 44 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 45 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 46 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 47 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 48 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 49 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 50 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 50:\n",
      "Performance of RandomAgent: -12.719999999999999\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 51 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 52 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 53 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 54 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 55 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 56 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 57 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 58 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 59 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 60 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 60:\n",
      "Performance of RandomAgent: -7.6\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 61 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 62 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 63 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 64 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 65 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 66 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 67 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 68 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 69 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 70 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 70:\n",
      "Performance of RandomAgent: -10.08\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 71 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 72 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 73 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 74 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 75 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 76 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 77 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 78 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 79 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 80 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 80:\n",
      "Performance of RandomAgent: -6.519999999999999\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 81 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 82 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 83 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 84 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 85 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 86 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 87 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 88 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 89 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 90 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Evaluation at step 90:\n",
      "Performance of RandomAgent: -7.719999999999999\n",
      "Performance of RuleBasedAgent: -1.9999999999999996\n",
      "Selected RuleBasedAgent as the best agent.\n",
      "Step 91 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 92 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 93 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 94 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 95 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 96 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 97 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 98 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Step 99 - State: [0.6 0.6], Rewards: [-0.09999999999999998, -0.09999999999999998]\n",
      "Step 100 - State: [0.5 0.5], Rewards: [-0.0, -0.0]\n",
      "Simulation completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class SimpleMultiAgentEnv(gym.Env):\n",
    "    def __init__(self, max_steps=20):\n",
    "        super(SimpleMultiAgentEnv, self).__init__()\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(2,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.state = np.array([0.5, 0.5])\n",
    "        self.max_steps = max_steps\n",
    "        self.current_step = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = np.array([0.5, 0.5])\n",
    "        self.current_step = 0\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, actions):\n",
    "        rewards = [0, 0]\n",
    "        self.current_step += 1\n",
    "        \n",
    "        for i, action in enumerate(actions):\n",
    "            if action == 0:\n",
    "                self.state[i] -= 0.1\n",
    "            else:\n",
    "                self.state[i] += 0.1\n",
    "                \n",
    "            rewards[i] = -abs(self.state[i] - 0.5)  # reward is higher when closer to 0.5\n",
    "        \n",
    "        done = self.current_step >= self.max_steps\n",
    "        \n",
    "        return self.state, rewards, done, {}\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "class RandomAgent:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "    \n",
    "    def act(self, state):\n",
    "        return [self.action_space.sample(), self.action_space.sample()]\n",
    "\n",
    "class RuleBasedAgent:\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "    \n",
    "    def act(self, state):\n",
    "        # Simple rule: move towards the center value (0.5)\n",
    "        actions = []\n",
    "        for s in state:\n",
    "            if s > 0.5:\n",
    "                actions.append(0)  # move down\n",
    "            else:\n",
    "                actions.append(1)  # move up\n",
    "        return actions\n",
    "\n",
    "def evaluate_agent(agent, env, num_episodes=5):\n",
    "    total_reward = 0\n",
    "    for _ in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        a=0\n",
    "        while not done:\n",
    "            print(a)\n",
    "            a+=1\n",
    "            actions = agent.act(state)\n",
    "            state, rewards, done, _ = env.step(actions)\n",
    "            episode_reward += sum(rewards)\n",
    "        total_reward += episode_reward\n",
    "    return total_reward / num_episodes\n",
    "\n",
    "# Instantiate the environment and agents\n",
    "env = SimpleMultiAgentEnv(max_steps=20)\n",
    "agent1 = RandomAgent(env.action_space)\n",
    "agent2 = RuleBasedAgent(env.action_space)\n",
    "\n",
    "# Initial agent selection\n",
    "best_agent = agent1\n",
    "\n",
    "# Parameters\n",
    "num_steps = 100\n",
    "evaluation_interval = 10  # Evaluate every 10 steps\n",
    "\n",
    "# Reset the environment\n",
    "state = env.reset()\n",
    "print(f\"Initial state: {state}\")\n",
    "\n",
    "for step in range(num_steps):\n",
    "    # Periodically evaluate and switch agents if necessary\n",
    "    if step % evaluation_interval == 0:\n",
    "        performance1 = evaluate_agent(agent1, env)\n",
    "        performance2 = evaluate_agent(agent2, env)\n",
    "        \n",
    "        print(f\"Evaluation at step {step}:\")\n",
    "        print(f\"Performance of RandomAgent: {performance1}\")\n",
    "        print(f\"Performance of RuleBasedAgent: {performance2}\")\n",
    "        \n",
    "        if performance1 > performance2:\n",
    "            best_agent = agent1\n",
    "            print(\"Selected RandomAgent as the best agent.\")\n",
    "        else:\n",
    "            best_agent = agent2\n",
    "            print(\"Selected RuleBasedAgent as the best agent.\")\n",
    "    \n",
    "    # Best agent takes actions\n",
    "    actions = best_agent.act(state)\n",
    "    \n",
    "    # Step the environment\n",
    "    state, rewards, done, _ = env.step(actions)\n",
    "    \n",
    "    print(f\"Step {step + 1} - State: {state}, Rewards: {rewards}\")\n",
    "\n",
    "print(\"Simulation completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    lstm_action = i\n",
    "    minrtt_action = 0\n",
    "    if i % 5 == 0:\n",
    "        current_action = lstm_action\n",
    "    print(current_action)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpquic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
